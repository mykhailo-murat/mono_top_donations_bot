# main.py
import logging
import pandas as pd
from telegram import Update, Document, InputFile
from telegram.ext import (
    ApplicationBuilder,
    MessageHandler,
    ContextTypes,
    filters,
)
from io import BytesIO, StringIO
import csv

# Logging setup
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

TOKEN = "7870393276:AAFJJMETllErbVSomsPgkcJur2xwvmDhutE"

# Handle CSV documents
async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    document: Document = update.message.document
    file = await context.bot.get_file(document.file_id)
    file_content = await file.download_as_bytearray()

    try:
        decoded = file_content.decode("utf-8")
        lines = decoded.splitlines()
        good_lines = []
        bad_lines = []

        reader = csv.reader(lines, quotechar='"', escapechar='\\')
        for i, row in enumerate(reader, start=1):
            if len(row) == 8:
                good_lines.append(row)
            else:
                bad_lines.append((i, lines[i-1]))

        df = pd.DataFrame(good_lines[1:], columns=good_lines[0])

        df = df[df["–î–æ–¥–∞—Ç–∫–æ–≤–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è"].str.contains("–í—ñ–¥:", na=False)].copy()
        df["–î–æ–Ω–∞—Ç–æ—Ä"] = df["–î–æ–¥–∞—Ç–∫–æ–≤–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è"].str.extract(r"–í—ñ–¥:\s*(.+)")

        summary = (
            df.groupby("–î–æ–Ω–∞—Ç–æ—Ä")["–°—É–º–∞"]
            .astype(float)
            .agg(['sum', 'count'])
            .sort_values(by="sum", ascending=False)
        )
        summary.reset_index(inplace=True)
        summary.columns = ["–Ü–º‚Äô—è", "–°—É–º–∞ (–≥—Ä–Ω)", "–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–ø–æ–≤–Ω–µ–Ω—å"]

        text = "\U0001F4B0 <b>–¢–û–ü –¥–æ–Ω–∞—Ç–µ—Ä–∏</b>\n\n"
        for idx, row in summary.iterrows():
            text += f"<b>{idx+1}. {row['–Ü–º‚Äô—è']}</b> ‚Äî {row['–°—É–º–∞ (–≥—Ä–Ω)']} –≥—Ä–Ω ({row['–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–ø–æ–≤–Ω–µ–Ω—å']} —Ä–∞–∑—ñ–≤)\n"

        if bad_lines:
            text += f"\n‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ {len(bad_lines)} —Ä—è–¥–∫—ñ–≤ —á–µ—Ä–µ–∑ –ø–æ–º–∏–ª–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏:\n"
            preview = '\n'.join([f"{i}: {line}" for i, line in bad_lines[:5]])
            text += preview
            if len(bad_lines) > 5:
                text += f"\n...—Ç–∞ —â–µ {len(bad_lines) - 5} —Ä—è–¥–∫—ñ–≤."

            # –î–æ–¥–∞—î–º–æ —è–∫ —Ç–µ–∫—Å—Ç–æ–≤–∏–π —Ñ–∞–π–ª —É—Å—ñ –ø–æ–≥–∞–Ω—ñ —Ä—è–¥–∫–∏
            bad_output = '\n'.join([f"{i}: {line}" for i, line in bad_lines])
            bad_file = BytesIO(bad_output.encode("utf-8"))
            bad_file.name = "bad_rows.txt"
            await update.message.reply_document(document=InputFile(bad_file))

        await update.message.reply_text(text, parse_mode='HTML')

    except Exception as e:
        logging.exception("–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ —Ñ–∞–π–ª—É")
        await update.message.reply_text("‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ —Ñ–∞–π–ª—É. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –π–æ–≥–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É.")


# Handle any other message
async def handle_fallback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("üëã –ù–∞–¥—ñ—à–ª—ñ—Ç—å, –±—É–¥—å –ª–∞—Å–∫–∞, .CSV-—Ñ–∞–π–ª –∑–≤—ñ—Ç—É –≤—ñ–¥ Mono –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É –¥–æ–Ω–∞—Ç—ñ–≤.")


if __name__ == '__main__':
    app = ApplicationBuilder().token(TOKEN).build()

    # CSV handler (–ª–æ–≤–∏—Ç—å –±—É–¥—å-—è–∫—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏, –¥–∞–ª—ñ ‚Äî —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è —É —Ñ—É–Ω–∫—Ü—ñ—ó)
    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))

    # Fallback –¥–ª—è –≤—Å—å–æ–≥–æ —ñ–Ω—à–æ–≥–æ
    app.add_handler(MessageHandler(filters.ALL, handle_fallback))

    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω–æ...")
    app.run_polling()
